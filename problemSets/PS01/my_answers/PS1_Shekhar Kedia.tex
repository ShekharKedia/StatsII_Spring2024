\documentclass[12pt,letterpaper]{article}
\usepackage{graphicx,textcomp}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{color}
\usepackage[reqno]{amsmath}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{amssymb,enumerate}
\usepackage[all]{xy}
\usepackage{endnotes}
\usepackage{lscape}
\newtheorem{com}{Comment}
\usepackage{float}
\usepackage{hyperref}
\newtheorem{lem} {Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{cor}{Corollary}
\newtheorem{obs}{Observation}
\usepackage[compact]{titlesec}
\usepackage{dcolumn}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{multirow}
\usepackage{xcolor}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\definecolor{light-gray}{gray}{0.65}
\usepackage{url}
\usepackage{listings}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}
\lstset{style=mystyle}
\newcommand{\Sref}[1]{Section~\ref{#1}}
\newtheorem{hyp}{Hypothesis}

\title{Problem Set 1}
\date{Due: February 11, 2024}
\author{Student: Shekhar Kedia (23351315)\\Applied Stats II}


\begin{document}
	\maketitle
	\section*{Instructions}
	\begin{itemize}
	\item Please show your work! You may lose points by simply writing in the answer. If the problem requires you to execute commands in \texttt{R}, please include the code you used to get your answers. Please also include the \texttt{.R} file that contains your code. If you are not sure if work needs to be shown for a particular problem, please ask.
\item Your homework should be submitted electronically on GitHub in \texttt{.pdf} form.
\item This problem set is due before 23:59 on Sunday February 11, 2024. No late assignments will be accepted.
	\end{itemize}

	\vspace{.25cm}
\section*{Question 1} 
\vspace{.25cm}
\noindent The Kolmogorov-Smirnov test uses cumulative distribution statistics test the similarity of the empirical distribution of some observed data and a specified PDF, and serves as a goodness of fit test. The test statistic is created by:

$$D = \max_{i=1:n} \Big\{ \frac{i}{n}  - F_{(i)}, F_{(i)} - \frac{i-1}{n} \Big\}$$

\noindent where $F$ is the theoretical cumulative distribution of the distribution being tested and $F_{(i)}$ is the $i$th ordered value. Intuitively, the statistic takes the largest absolute difference between the two distribution functions across all $x$ values. Large values indicate dissimilarity and the rejection of the hypothesis that the empirical distribution matches the queried theoretical distribution. The p-value is calculated from the Kolmogorov-
Smirnoff CDF:

$$p(D \leq d)= \frac{\sqrt {2\pi}}{d} \sum _{k=1}^{\infty }e^{-(2k-1)^{2}\pi ^{2}/(8d^{2})}$$


\noindent which generally requires approximation methods (see \href{https://core.ac.uk/download/pdf/25787785.pdf}{Marsaglia, Tsang, and Wang 2003}). This so-called non-parametric test (this label comes from the fact that the distribution of the test statistic does not depend on the distribution of the data being tested) performs poorly in small samples, but works well in a simulation environment. Write an \texttt{R} function that implements this test where the reference distribution is normal. Using \texttt{R} generate 1,000 Cauchy random variables (\texttt{rcauchy(1000, location = 0, scale = 1)}) and perform the test (remember, use the same seed, something like \texttt{set.seed(123)}, whenever you're generating your own data).\\
	
	
\noindent As a hint, you can create the empirical distribution and theoretical CDF using this code:

\begin{lstlisting}[language=R]
	# create empirical distribution of observed data
	ECDF <- ecdf(data)
	empiricalCDF <- ECDF(data)
	# generate test statistic
	D <- max(abs(empiricalCDF - pnorm(data))) \end{lstlisting}

\vspace*{.2cm}
\noindent\textbf{Solution:\\}
Firstly using \texttt{R}, I create 1,000 Cauchy random variables running the following codes:
\lstinputlisting[language=R, firstline=39, lastline=42]{PS1_Shekhar Kedia.R}

\noindent Next, I create the function to perform Kolmogorov-Smirnov test running the following codes:\\
\textit{N.B.: The function produces two output, one the test statistics (D) and p-value}
\lstinputlisting[language=R, firstline=46, lastline=60]{PS1_Shekhar Kedia.R}

\noindent Now, I compare the results of the test using the created function and using in-built \texttt{R} function.\\
The result of the created K-S test function is:
\lstinputlisting[language=R, firstline=62, lastline=63]{PS1_Shekhar Kedia.R}

\noindent Output:
\begin{lstlisting}
D = 0.1347281
p-value = 0.003801528\end{lstlisting}
And, the result of K-S test using the in-built \texttt{R} function is:
\lstinputlisting[language=R, firstline=65, lastline=66]{PS1_Shekhar Kedia.R}

\noindent Output:
\begin{lstlisting}
Asymptotic one-sample Kolmogorov-Smirnov test
data: empirical
D = 0.13573, p-value = 2.22e-16
alternative hypothesis: two-sided\end{lstlisting}
We can see that the output of the function created manually and the in-built function is approximately similar. The minor differences in the decimal values is because of rounding and can be ignored. 
\vspace{1cm}

\section*{Question 2}
\noindent Estimate an OLS regression in \texttt{R} that uses the Newton-Raphson algorithm (specifically \texttt{BFGS}, which is a quasi-Newton method), and show that you get the equivalent results to using \texttt{lm}. Use the code below to create your data.
\vspace{.5cm}
\lstinputlisting[language=R, firstline=74,lastline=76]{PS1_Shekhar Kedia.R} 


\vspace*{.2cm}
\noindent\textbf{Solution:\\}
Firstly, I run the above code to create the data. Then, I create a function to calculate the sum of squared residuals using the following \texttt{R} codes:
\lstinputlisting[language=R, firstline=78, lastline=81]{PS1_Shekhar Kedia.R}

\noindent Then, I estimate the coefficients using the BFGS algorithm and plotting the results on a scatter plot to get an idea of the OLS regression using the following \texttt{R} codes:
\lstinputlisting[language=R, firstline=83, lastline=91]{PS1_Shekhar Kedia.R}
\pagebreak
\noindent Output:
\begin{lstlisting}
intercept     slope 
0.1391778 	2.7267000 
\end{lstlisting}

\noindent Scatter plot showing relationship between Y and X and the OLS regression line using BFGS algorithm:
\begin{center}
	\includegraphics[width=12cm]{plot_Y_X_bfgs.pdf}  
\end{center}

\noindent Finally, I estimate the coefficients using the in-built lm() function to ensure I get the same results and also, plotting the output to see the similarity between the two models.\\
Following \texttt{R} codes is used:
\lstinputlisting[language=R, firstline=93, lastline=101]{PS1_Shekhar Kedia.R}
\pagebreak
\noindent Output:
\begin{lstlisting}
(Intercept)           x 
0.1391874   	2.7266985 
\end{lstlisting}

\noindent Scatter plot showing relationship between Y and X and the OLS regression line using lm() function:
\begin{center}
	\includegraphics[width=12cm]{plot_Y_X_lm.pdf}  
\end{center}
We can see that both the models (using BFGS algorithm and lm() function in \texttt{R}) produced equivalent results to estimate the OLS regression.

\end{document}
